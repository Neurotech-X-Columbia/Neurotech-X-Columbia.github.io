- name: "Brain2Speech: Decoding Brain Signals into Speech"
  description: >
    This project focuses on non-invasive brain-to-speech decoding from MEG signals, mapping neural activity directly to auditory speech units using the [LibriBrain dataset](https://neural-processing-lab.github.io/2025-libribrain-competition/). Our goal is to advance MEG-based speech decoding and identify the temporal and spatial patterns in the brain that support recovering speech elements.
  lead: Yizi Zhang
  status: Active
  keywords: ['BCI', 'MEG', 'Speech Processing']

- name: "Audio-Visual Brain Encoding"
  description: >
    This project investigates how visual speech, such as lip movements, contributes to brain activity during natural language comprehension. By integrating frame-level visual features from the mouth region with linguistic representations from deep language models, we build multimodal encoding models to test whether visual information provides unique predictive power beyond auditory and linguistic cues.
  lead: Linyang He
  status: Active
  keywords: ['Brain Encoding', 'ECoG', 'Speech Processing', 'NeuroAI']

- name: "SymPath: A Brain-Aware Emotional Audio Companion"
  description: >
    This project aims to create an emotion-adaptive conversational system that bridges brain–computer interfaces and audio foundation models. We first develop an EEG-based emotion recognition framework to infer users’ affective states from neural activity. Then, we train a speech-based dialogue model capable of adjusting its responses—both in tone and linguistic style—according to detected emotions. By integrating these two systems, we introduce a neuro-adaptive audio chatbot that responds empathetically and modulates its voice in real time based on how the user feels.
  lead: Sukru Samet Dindar
  status: Active
  keywords: ['BCI', 'EEG', 'Emotion Detection', 'Conversational AI']

- name: "BrainSight: Image-to-Brain Visual Encoding"
  description: >
    This project aims to understand how the human brain encodes visual information by building models that predict brain activity (e.g., fMRI, EEG signals) from naturalistic images. By linking state-of-the-art computer vision models with neural data, we seek to uncover which image features best explain activity in different brain regions and how artificial systems align or diverge from human visual processing. 
  lead: Pinyuan Feng
  status: Active
  keywords: ['Brain Encoding', 'Computational Vision', 'GenAI']

- name: "Generative Decoders of Visual Cortical Representations"
  description: >
    This project investigates how neural signals can be transformed back into visual images using deep learning. Leveraging the THINGS Ventral Stream Spiking Dataset [(TVSD)](https://doi.gin.g-node.org/10.12751/g-node.hc7zlv/) — which records single-neuron activity from macaque visual areas V1, V4, and IT — the team developed a generative decoding pipeline that maps brain activity to perceived images. By integrating AlexNet, VDVAE, and Versatile Diffusion, the project revealed strong parallels between mid-level visual features in artificial networks and biological vision, advancing our understanding of how the brain encodes and reconstructs the visual world.
  lead: Michael Zhou
  status: Completed
  keywords: ['BCI', 'Diffusion Models', 'Single Neuron']

- name: "Multiphase-EEG: SSVEP Speller"
  description: >
    This project develops an SSVEP-based speller system. The goal is to use brain wave data collected from an OpenBCI headset to control an online keyboard interface. The system includes data acquisition, visual stimulus presentation, and signal decoding pipelines for steady-state visually evoked potentials (SSVEP), enabling users to type characters using only their brain activity.
  lead: Matheu Campbell
  status: Completed
  keywords: ['BCI', 'EEG', 'SSVEP', 'Speller']

- name: "Drone: EEG-Controlled Flight"
  description: >
    Develop a program that can interpret brain signals from an EEG headset and convert them into control instructions for a drone in real time. The system integrates data collection, signal processing, and control interfaces to enable closed-loop brain-to-drone communication.
  lead: Matheu Campbell
  status: Completed
  keywords: ['BCI', 'EEG', 'Drone Control']

